### 适合python编辑的configmap的写法
#### 1、原始的configmap有1个弊端，就是有管道符"｜"，不适合python的编辑
![image](https://github.com/498946975/DevOps/blob/master/images/configmap1.png)
#### 2、创建测试文件夹
```shell script
[root@k8s-master01 Prometheus]# mkdir cfgmap-test
[root@k8s-master01 Prometheus]# cd cfgmap-test  
```
#### 3、原始的prometheus-alertmanager-cfg.yaml里面有2个yml文件
```shell script
1. prometheus.yml # prometheus需要采集的指标
2. rules.yml      # 告警规则
```
#### 4、在/root/Prometheus/cfgmap-test，创建prometheus.yml 
```shell script
[root@k8s-master01 cfgmap-test]# vim prometheus.yml 
```
```yaml
rule_files:
- /etc/prometheus/rules.yml
alerting:
  alertmanagers:
  - static_configs:
    - targets: ["localhost:9093"]
global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 1m
scrape_configs:
- job_name: 'kubernetes-node'
  kubernetes_sd_configs:
  - role: node
  relabel_configs:
  - source_labels: [__address__]
    regex: '(.*):10250'
    replacement: '${1}:9100'
    target_label: __address__
    action: replace
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
- job_name: 'kubernetes-node-cadvisor'
  kubernetes_sd_configs:
  - role:  node
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - target_label: __address__
    replacement: kubernetes.default.svc:443
  - source_labels: [__meta_kubernetes_node_name]
    regex: (.+)
    target_label: __metrics_path__
    replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
- job_name: 'kubernetes-apiserver'
  kubernetes_sd_configs:
  - role: endpoints
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  relabel_configs:
  - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
    action: keep
    regex: default;kubernetes;https
- job_name: 'kubernetes-service-endpoints'
  kubernetes_sd_configs:
  - role: endpoints
  relabel_configs:
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
    action: keep
    regex: true
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
    action: replace
    target_label: __scheme__
    regex: (https?)
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
    action: replace
    target_label: __metrics_path__
    regex: (.+)
  - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
    action: replace
    target_label: __address__
    regex: ([^:]+)(?::\d+)?;(\d+)
    replacement: $1:$2
  - action: labelmap
    regex: __meta_kubernetes_service_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_service_name]
    action: replace
    target_label: kubernetes_name 
- job_name: 'kubernetes-pods'
  kubernetes_sd_configs:
  - role: pod
  relabel_configs:
  - action: keep
    regex: true
    source_labels:
    - __meta_kubernetes_pod_annotation_prometheus_io_scrape
  - action: replace
    regex: (.+)
    source_labels:
    - __meta_kubernetes_pod_annotation_prometheus_io_path
    target_label: __metrics_path__
  - action: replace
    regex: ([^:]+)(?::\d+)?;(\d+)
    replacement: $1:$2
    source_labels:
    - __address__
    - __meta_kubernetes_pod_annotation_prometheus_io_port
    target_label: __address__
  - action: labelmap
    regex: __meta_kubernetes_pod_label_(.+)
  - action: replace
    source_labels:
    - __meta_kubernetes_namespace
    target_label: kubernetes_namespace
  - action: replace
    source_labels:
    - __meta_kubernetes_pod_name
    target_label: kubernetes_pod_name
- job_name: 'kubernetes-kube-proxy'
  scrape_interval: 5s
  static_configs:
  - targets: ['172.16.120.101:10249','172.16.120.102:10249','172.16.120.111:10249','172.16.120.112:10249']
- job_name: 'mysql'
  static_configs:
  - targets: ['172.16.120.112:9104']
- job_name: 'kubernetes-etcd'
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/k8s-certs/etcd/ca.crt
    cert_file: /var/run/secrets/kubernetes.io/k8s-certs/etcd/server.crt
    key_file: /var/run/secrets/kubernetes.io/k8s-certs/etcd/server.key
  scrape_interval: 5s
  static_configs:
  - targets: ['172.16.120.101:2379','172.16.120.102:2379']
```
#### 5、在/root/Prometheus/cfgmap-test，创建rules.yml 
```shell script
[root@k8s-master01 cfgmap-test]# vim rules.yml 
```
```yaml
groups:
- name: example
  rules:
  - alert: kube-proxy的cpu使用率大于80%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-kube-proxy"}[1m]) * 100 > 80
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过80%"
  - alert:  kube-proxy的cpu使用率大于90%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-kube-proxy"}[1m]) * 100 > 90
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过90%"
  - alert: scheduler的cpu使用率大于80%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-schedule"}[1m]) * 100 > 80
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过80%"
  - alert:  scheduler的cpu使用率大于90%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-schedule"}[1m]) * 100 > 90
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过90%"
  - alert: controller-manager的cpu使用率大于80%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-controller-manager"}[1m]) * 100 > 80
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过80%"
  - alert:  controller-manager的cpu使用率大于90%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-controller-manager"}[1m]) * 100 > 0
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过90%"
  - alert: apiserver的cpu使用率大于80%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-apiserver"}[1m]) * 100 > 80
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过80%"
  - alert:  apiserver的cpu使用率大于90%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-apiserver"}[1m]) * 100 > 90
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过90%"
  - alert: etcd的cpu使用率大于80%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-etcd"}[1m]) * 100 > 80
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过80%"
  - alert:  etcd的cpu使用率大于90%
    expr: rate(process_cpu_seconds_total{job=~"kubernetes-etcd"}[1m]) * 100 > 90
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}组件的cpu使用率超过90%"
  - alert: kube-state-metrics的cpu使用率大于80%
    expr: rate(process_cpu_seconds_total{k8s_app=~"kube-state-metrics"}[1m]) * 100 > 80
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.k8s_app}}组件的cpu使用率超过80%"
      value: "{{ $value }}%"
      threshold: "80%"      
  - alert: kube-state-metrics的cpu使用率大于90%
    expr: rate(process_cpu_seconds_total{k8s_app=~"kube-state-metrics"}[1m]) * 100 > 0
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.k8s_app}}组件的cpu使用率超过90%"
      value: "{{ $value }}%"
      threshold: "90%"      
  - alert: coredns的cpu使用率大于80%
    expr: rate(process_cpu_seconds_total{k8s_app=~"kube-dns"}[1m]) * 100 > 80
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.k8s_app}}组件的cpu使用率超过80%"
      value: "{{ $value }}%"
      threshold: "80%"      
  - alert: coredns的cpu使用率大于90%
    expr: rate(process_cpu_seconds_total{k8s_app=~"kube-dns"}[1m]) * 100 > 90
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.k8s_app}}组件的cpu使用率超过90%"
      value: "{{ $value }}%"
      threshold: "90%"      
  - alert: kube-proxy打开句柄数>600
    expr: process_open_fds{job=~"kubernetes-kube-proxy"}  > 600
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>600"
      value: "{{ $value }}"
  - alert: kube-proxy打开句柄数>1000
    expr: process_open_fds{job=~"kubernetes-kube-proxy"}  > 1000
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>1000"
      value: "{{ $value }}"
  - alert: kubernetes-schedule打开句柄数>600
    expr: process_open_fds{job=~"kubernetes-schedule"}  > 600
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>600"
      value: "{{ $value }}"
  - alert: kubernetes-schedule打开句柄数>1000
    expr: process_open_fds{job=~"kubernetes-schedule"}  > 1000
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>1000"
      value: "{{ $value }}"
  - alert: kubernetes-controller-manager打开句柄数>600
    expr: process_open_fds{job=~"kubernetes-controller-manager"}  > 600
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>600"
      value: "{{ $value }}"
  - alert: kubernetes-controller-manager打开句柄数>1000
    expr: process_open_fds{job=~"kubernetes-controller-manager"}  > 1000
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>1000"
      value: "{{ $value }}"
  - alert: kubernetes-apiserver打开句柄数>600
    expr: process_open_fds{job=~"kubernetes-apiserver"}  > 600
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>600"
      value: "{{ $value }}"
  - alert: kubernetes-apiserver打开句柄数>1000
    expr: process_open_fds{job=~"kubernetes-apiserver"}  > 1000
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>1000"
      value: "{{ $value }}"
  - alert: kubernetes-etcd打开句柄数>600
    expr: process_open_fds{job=~"kubernetes-etcd"}  > 600
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>600"
      value: "{{ $value }}"
  - alert: kubernetes-etcd打开句柄数>1000
    expr: process_open_fds{job=~"kubernetes-etcd"}  > 1000
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "{{$labels.instance}}的{{$labels.job}}打开句柄数>1000"
      value: "{{ $value }}"
  - alert: coredns
    expr: process_open_fds{k8s_app=~"kube-dns"}  > 600
    for: 2s
    labels:
      severity: warnning 
    annotations:
      description: "插件{{$labels.k8s_app}}({{$labels.instance}}): 打开句柄数超过600"
      value: "{{ $value }}"
  - alert: coredns
    expr: process_open_fds{k8s_app=~"kube-dns"}  > 1000
    for: 2s
    labels:
      severity: critical
    annotations:
      description: "插件{{$labels.k8s_app}}({{$labels.instance}}): 打开句柄数超过1000"
      value: "{{ $value }}"
  - alert: kube-proxy
    expr: process_virtual_memory_bytes{job=~"kubernetes-kube-proxy"}  > 2000000000
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 使用虚拟内存超过2G"
      value: "{{ $value }}"
  - alert: scheduler
    expr: process_virtual_memory_bytes{job=~"kubernetes-schedule"}  > 2000000000
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 使用虚拟内存超过2G"
      value: "{{ $value }}"
  - alert: kubernetes-controller-manager
    expr: process_virtual_memory_bytes{job=~"kubernetes-controller-manager"}  > 2000000000
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 使用虚拟内存超过2G"
      value: "{{ $value }}"
  - alert: kubernetes-apiserver
    expr: process_virtual_memory_bytes{job=~"kubernetes-apiserver"}  > 2000000000
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 使用虚拟内存超过2G"
      value: "{{ $value }}"
  - alert: kubernetes-etcd
    expr: process_virtual_memory_bytes{job=~"kubernetes-etcd"}  > 2000000000
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 使用虚拟内存超过2G"
      value: "{{ $value }}"
  - alert: kube-dns
    expr: process_virtual_memory_bytes{k8s_app=~"kube-dns"}  > 2000000000
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "插件{{$labels.k8s_app}}({{$labels.instance}}): 使用虚拟内存超过2G"
      value: "{{ $value }}"
  - alert: HttpRequestsAvg
    expr: sum(rate(rest_client_requests_total{job=~"kubernetes-kube-proxy|kubernetes-kubelet|kubernetes-schedule|kubernetes-control-manager|kubernetes-apiservers"}[1m]))  > 1000
    for: 2s
    labels:
      team: admin
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): TPS超过1000"
      value: "{{ $value }}"
      threshold: "1000"   
  - alert: Pod_restarts
    expr: kube_pod_container_status_restarts_total{namespace=~"kube-system|default|monitor-sa"} > 0
    for: 2s
    labels:
      severity: warnning
    annotations:
      description: "在{{$labels.namespace}}名称空间下发现{{$labels.pod}}这个pod下的容器{{$labels.container}}被重启,这个监控指标是由{{$labels.instance}}采集的"
      value: "{{ $value }}"
      threshold: "0"
  - alert: Pod_waiting
    expr: kube_pod_container_status_waiting_reason{namespace=~"kube-system|default"} == 1
    for: 2s
    labels:
      team: admin
    annotations:
      description: "空间{{$labels.namespace}}({{$labels.instance}}): 发现{{$labels.pod}}下的{{$labels.container}}启动异常等待中"
      value: "{{ $value }}"
      threshold: "1"   
  - alert: Pod_terminated
    expr: kube_pod_container_status_terminated_reason{namespace=~"kube-system|default|monitor-sa"} == 1
    for: 2s
    labels:
      team: admin
    annotations:
      description: "空间{{$labels.namespace}}({{$labels.instance}}): 发现{{$labels.pod}}下的{{$labels.container}}被删除"
      value: "{{ $value }}"
      threshold: "1"
  - alert: Etcd_leader
    expr: etcd_server_has_leader{job="kubernetes-etcd"} == 0
    for: 2s
    labels:
      team: admin
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 当前没有leader"
      value: "{{ $value }}"
      threshold: "0"
  - alert: Etcd_leader_changes
    expr: rate(etcd_server_leader_changes_seen_total{job="kubernetes-etcd"}[1m]) > 0
    for: 2s
    labels:
      team: admin
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 当前leader已发生改变"
      value: "{{ $value }}"
      threshold: "0"
  - alert: Etcd_failed
    expr: rate(etcd_server_proposals_failed_total{job="kubernetes-etcd"}[1m]) > 0
    for: 2s
    labels:
      team: admin
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}}): 服务失败"
      value: "{{ $value }}"
      threshold: "0"
  - alert: Etcd_db_total_size
    expr: etcd_debugging_mvcc_db_total_size_in_bytes{job="kubernetes-etcd"} > 10000000000
    for: 2s
    labels:
      team: admin
    annotations:
      description: "组件{{$labels.job}}({{$labels.instance}})：db空间超过10G"
      value: "{{ $value }}"
      threshold: "10G"
  - alert: Endpoint_ready
    expr: kube_endpoint_address_not_ready{namespace=~"kube-system|default"} == 1
    for: 2s
    labels:
      team: admin
    annotations:
      description: "空间{{$labels.namespace}}({{$labels.instance}}): 发现{{$labels.endpoint}}不可用"
      value: "{{ $value }}"
      threshold: "1"
- name: 物理节点状态-监控告警
  rules:
  - alert: 物理节点cpu使用率
    expr: 100-avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by(instance)*100 > 90
    for: 2s
    labels:
      severity: ccritical
    annotations:
      summary: "{{ $labels.instance }}cpu使用率过高"
      description: "{{ $labels.instance }}的cpu使用率超过90%,当前使用率[{{ $value }}],需要排查处理" 
  - alert: 物理节点内存使用率
    expr: (node_memory_MemTotal_bytes - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)) / node_memory_MemTotal_bytes * 100 > 90
    for: 2s
    labels:
      severity: critical
    annotations:
      summary: "{{ $labels.instance }}内存使用率过高"
      description: "{{ $labels.instance }}的内存使用率超过90%,当前使用率[{{ $value }}],需要排查处理"
  - alert: InstanceDown
    expr: up == 0
    for: 2s
    labels:
      severity: critical
    annotations:   
      summary: "{{ $labels.instance }}: 服务器宕机"
      description: "{{ $labels.instance }}: 服务器延时超过2分钟"
  - alert: 物理节点磁盘的IO性能
    expr: 100-(avg(irate(node_disk_io_time_seconds_total[1m])) by(instance)* 100) < 60
    for: 2s
    labels:
      severity: critical
    annotations:
      summary: "{{$labels.mountpoint}} 流入磁盘IO使用率过高！"
      description: "{{$labels.mountpoint }} 流入磁盘IO大于60%(目前使用:{{$value}})"
  - alert: 入网流量带宽
    expr: ((sum(rate (node_network_receive_bytes_total{device!~'tap.*|veth.*|br.*|docker.*|virbr*|lo*'}[5m])) by (instance)) / 100) > 102400
    for: 2s
    labels:
      severity: critical
    annotations:
      summary: "{{$labels.mountpoint}} 流入网络带宽过高！"
      description: "{{$labels.mountpoint }}流入网络带宽持续5分钟高于100M. RX带宽使用率{{$value}}"
  - alert: 出网流量带宽
    expr: ((sum(rate (node_network_transmit_bytes_total{device!~'tap.*|veth.*|br.*|docker.*|virbr*|lo*'}[5m])) by (instance)) / 100) > 102400
    for: 2s
    labels:
      severity: critical
    annotations:
      summary: "{{$labels.mountpoint}} 流出网络带宽过高！"
      description: "{{$labels.mountpoint }}流出网络带宽持续5分钟高于100M. RX带宽使用率{{$value}}"
  - alert: TCP会话
    expr: node_netstat_Tcp_CurrEstab > 1000
    for: 2s
    labels:
      severity: critical
    annotations:
      summary: "{{$labels.mountpoint}} TCP_ESTABLISHED过高！"
      description: "{{$labels.mountpoint }} TCP_ESTABLISHED大于1000%(目前使用:{{$value}}%)"
  - alert: 磁盘容量
    expr: 100-(node_filesystem_free_bytes{fstype=~"ext4|xfs"}/node_filesystem_size_bytes {fstype=~"ext4|xfs"}*100) > 80
    for: 2s
    labels:
      severity: critical
    annotations:
      summary: "{{$labels.mountpoint}} 磁盘分区使用率过高！"
      description: "{{$labels.mountpoint }} 磁盘分区使用大于80%(目前使用:{{$value}}%)"
```
#### 6、用create创建configmap
```shell script
[root@k8s-master01 cfgmap-test]# kubectl create configmap prometheus-config --from-file=/root/Prometheus/cfgmap-test/ -n monitor-sa
```
#### 7、用create创建的configmap没有label，所以需要打标签
```shell script
[root@k8s-master01 cfgmap-test]# kubectl label cm/prometheus-config -n monitor-sa app=prometheus
```
```shell script
[root@k8s-master01 cfgmap-test]# kubectl get cm -n monitor-sa --show-labels  
NAME                DATA   AGE     LABELS
alertmanager        1      28h     <none>
kube-root-ca.crt    1      4d22h   <none>
prometheus-config   2      15m     app=prometheus
```
#### 8、然后暴力重启prometheus即可
```shell script
[root@k8s-master01 cfgmap-test]# kubectl delete -f prometheus-alertmanager-deploy.yaml
[root@k8s-master01 cfgmap-test]# kubectl apply -f prometheus-alertmanager-deploy.yaml 
```